# LLM Provider Configuration
LLM_PROVIDER=openai             # anthropic | openai

# OpenAI Settings
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o

# Anthropic Settings (alternative)
# ANTHROPIC_API_KEY=sk-ant-...
# ANTHROPIC_MODEL=claude-sonnet-4-6

# Whisper Settings
WHISPER_MODEL_SIZE=small         # tiny | base | small | medium | large-v2 | large-v3
WHISPER_DEVICE=auto             # auto | cpu | cuda
WHISPER_COMPUTE_TYPE=auto       # auto | float16 | int8

# Pipeline Settings
CHUNK_SIZE=6000                 # characters per LLM chunk
CHUNK_OVERLAP=200               # overlap characters between chunks

# Data Paths (relative to project root)
INPUT_DIR=data/input
OUTPUT_DIR=data/output
INTERMEDIATE_DIR=data/intermediate
PROCESSED_DIR=data/processed
FAILED_DIR=data/failed

# Logging
LOG_LEVEL=INFO                  # DEBUG | INFO | WARNING | ERROR
LOG_FILE=logs/pipeline.log
